{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ed438fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/reinhardts/Documents/myProject/NURS6806/exerPythCombineFiles/FileTypes'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/reinhardts/Documents/myProject/NURS6806/exerPythCombineFiles/FileTypes'\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9df2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in folder:  ['EXCELtest2.xlsx', 'CSVtest2.csv', 'EXCELtest.xlsx', 'XMLtest2.xml', 'XMLtest3.xml', 'JSONtest.json', 'JSONtest2.json', 'CSVtest.csv', 'JSONtest3.json', 'Combine multiple file types with same columns into dataframe.py', 'Combine multiple file types with same columns into dataframe.ipynb', 'XMLtest.xml'] \n",
      "\n",
      "CSV files:  ['CSVtest2.csv', 'CSVtest.csv'] \n",
      "Excel files:  ['EXCELtest2.xlsx', 'EXCELtest.xlsx'] \n",
      "JSON files:  ['JSONtest.json', 'JSONtest2.json', 'JSONtest3.json'] \n",
      "XML files:  ['XMLtest2.xml', 'XMLtest3.xml', 'XMLtest.xml']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List the files in the directory.\n",
    "files = os.listdir(file_path)\n",
    "print('All files in folder: ', files, '\\n')\n",
    "\n",
    "# List of file types we want to add\n",
    "file_types = ['xlsx','csv','json','xml']\n",
    "\n",
    "# create a list of files for each file type\n",
    "files_csv = [f for f in files if f[-3:] == 'csv']\n",
    "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
    "files_json = [f for f in files if f[-4:] == 'json']\n",
    "files_xml = [f for f in files if f[-3:] == 'xml']\n",
    "\n",
    "print('CSV files: ', files_csv, '\\nExcel files: ', files_xlsx, '\\nJSON files: ',files_json, '\\nXML files: ', files_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0641ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brock Bricks</td>\n",
       "      <td>4/10/2019</td>\n",
       "      <td>185</td>\n",
       "      <td>95</td>\n",
       "      <td>CSVtest2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack Brack</td>\n",
       "      <td>6/7/2019</td>\n",
       "      <td>172</td>\n",
       "      <td>91</td>\n",
       "      <td>CSVtest2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Smith</td>\n",
       "      <td>4/1/2019</td>\n",
       "      <td>185</td>\n",
       "      <td>91</td>\n",
       "      <td>CSVtest.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack Black</td>\n",
       "      <td>4/2/2019</td>\n",
       "      <td>183</td>\n",
       "      <td>91</td>\n",
       "      <td>CSVtest.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock Royden</td>\n",
       "      <td>2019-05-02 00:00:00</td>\n",
       "      <td>160</td>\n",
       "      <td>52</td>\n",
       "      <td>EXCELtest2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brandon Snads</td>\n",
       "      <td>2019-10-02 00:00:00</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>EXCELtest2.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jen Smith</td>\n",
       "      <td>2019-05-02 00:00:00</td>\n",
       "      <td>153</td>\n",
       "      <td>50</td>\n",
       "      <td>EXCELtest.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>2019-01-02 00:00:00</td>\n",
       "      <td>160</td>\n",
       "      <td>55</td>\n",
       "      <td>EXCELtest.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>09/02/2019</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>JSONtest.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jane Jackson</td>\n",
       "      <td>09/03/2019</td>\n",
       "      <td>172</td>\n",
       "      <td>74</td>\n",
       "      <td>JSONtest2.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Becky Jackson</td>\n",
       "      <td>04/03/2019</td>\n",
       "      <td>165</td>\n",
       "      <td>70</td>\n",
       "      <td>JSONtest3.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>John Smithe</td>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>185</td>\n",
       "      <td>101</td>\n",
       "      <td>XMLtest2.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brett Smithe</td>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>179</td>\n",
       "      <td>99</td>\n",
       "      <td>XMLtest3.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>02/08/2019</td>\n",
       "      <td>180</td>\n",
       "      <td>100</td>\n",
       "      <td>XMLtest.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                 date height weight           Source\n",
       "0    Brock Bricks            4/10/2019    185     95     CSVtest2.csv\n",
       "1      Jack Brack             6/7/2019    172     91     CSVtest2.csv\n",
       "2      Jack Smith             4/1/2019    185     91      CSVtest.csv\n",
       "3      Jack Black             4/2/2019    183     91      CSVtest.csv\n",
       "4     Rock Royden  2019-05-02 00:00:00    160     52  EXCELtest2.xlsx\n",
       "5   Brandon Snads  2019-10-02 00:00:00    175     80  EXCELtest2.xlsx\n",
       "6       Jen Smith  2019-05-02 00:00:00    153     50   EXCELtest.xlsx\n",
       "7       Sam Smith  2019-01-02 00:00:00    160     55   EXCELtest.xlsx\n",
       "8      Jane Smith           09/02/2019    170     75    JSONtest.json\n",
       "9    Jane Jackson           09/03/2019    172     74   JSONtest2.json\n",
       "10  Becky Jackson           04/03/2019    165     70   JSONtest3.json\n",
       "11    John Smithe           03/08/2019    185    101     XMLtest2.xml\n",
       "12   Brett Smithe           05/08/2019    179     99     XMLtest3.xml\n",
       "13     John Smith           02/08/2019    180    100      XMLtest.xml"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Iterate through the files in the directory and append each one into the dataframe.\n",
    "# This will only work correctly if the files have the exact same column names.\n",
    "df_list = []\n",
    "for f in files_csv:\n",
    "    data = pd.read_csv(str(file_path) + '/' + str(f), index_col=None, header=0)\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "for f in files_xlsx:\n",
    "    data = pd.read_excel(str(file_path) + '/' + str(f))\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "# Iterate through the json files and add data from each to a list.\n",
    "json_list = []\n",
    "for f in files_json:\n",
    "    with open(str(file_path) + '/' + str(f)) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        json_obj['Source'] = f\n",
    "        json_list.append(json_obj.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(json_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "    \n",
    "# Iterate through the xml files and add data from each to a list.\n",
    "xml_list = []\n",
    "for f in files_xml:\n",
    "    # create element tree object \n",
    "    tree = ET.parse(str(file_path) + '/' + str(f))\n",
    "    # get root element \n",
    "    root = tree.getroot()\n",
    "    # create dictionary from XML tags and values\n",
    "    itemdict = {}\n",
    "    for item in root:\n",
    "        itemdict[item.tag] = item.text\n",
    "    itemdict['Source'] = f\n",
    "    xml_list.append(itemdict.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(xml_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "\n",
    "# Combine all the data frames in the list into a single data frame.    \n",
    "df =  pd.concat(df_list, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# See how many rows the data frame has.\n",
    "print(len(df.index))\n",
    "\n",
    "# Show the data in the data frame.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa9a0c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-18\n",
      "/Users/reinhardts/Documents/myProject/NURS6806/exerPythCombineFiles/FileTypes/NewCombinedFile_2021-10-18.csv\n",
      "File saved.\n"
     ]
    }
   ],
   "source": [
    "#Save the dataframe to a new combined csv file.\n",
    "\n",
    "# Add today's date to the name of the new file.\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(today)\n",
    "\n",
    "filename = str(file_path) + '/' + 'NewCombinedFile_' + str(today) + '.csv'\n",
    "print(filename)\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "print('File saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerunning code with new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f06d1e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/reinhardts/Documents/myProject/NURS6806/exerPythCombineFiles/FileTypes'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/reinhardts/Documents/myProject/NURS6806/exerPythCombineFiles/FileTypes'\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f228cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in folder:  ['.DS_Store', 'XMLtest2.xml', 'XMLtestedit10:18.xml', 'CSVtest2edit10:18.numbers', 'XMLtest3.xml', 'JSONtest.json', 'JSONtest2.json', 'XMLtest3edit10:18.xml', 'JSONtest3.json', 'Combine multiple file types with same columns into dataframe.py', 'NewCombinedFile_2021-10-18.csv', 'JSONtestedit.json', 'Combine multiple file types with same columns into dataframe.ipynb', 'JSONtest3edit.json', 'JSONtest2edit.json', 'EXCELtestedit10:18.xlsx', '~$Ltest3.xml', 'XMLtest.xml', 'EXCELtest2edit10:18.xlsx', 'CSVtestedit10:18.numbers', 'XMLtest2edited10:18.xml'] \n",
      "\n",
      "CSV files:  ['NewCombinedFile_2021-10-18.csv'] \n",
      "Excel files:  ['EXCELtestedit10:18.xlsx', 'EXCELtest2edit10:18.xlsx'] \n",
      "JSON files:  ['JSONtest.json', 'JSONtest2.json', 'JSONtest3.json', 'JSONtestedit.json', 'JSONtest3edit.json', 'JSONtest2edit.json'] \n",
      "XML files:  ['XMLtest2.xml', 'XMLtestedit10:18.xml', 'XMLtest3.xml', 'XMLtest3edit10:18.xml', '~$Ltest3.xml', 'XMLtest.xml', 'XMLtest2edited10:18.xml']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List the files in the directory.\n",
    "files = os.listdir(file_path)\n",
    "print('All files in folder: ', files, '\\n')\n",
    "\n",
    "# List of file types we want to add\n",
    "file_types = ['xlsx','csv','json','xml']\n",
    "\n",
    "# create a list of files for each file type\n",
    "files_csv = [f for f in files if f[-3:] == 'csv']\n",
    "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
    "files_json = [f for f in files if f[-4:] == 'json']\n",
    "files_xml = [f for f in files if f[-3:] == 'xml']\n",
    "\n",
    "print('CSV files: ', files_csv, '\\nExcel files: ', files_xlsx, '\\nJSON files: ',files_json, '\\nXML files: ', files_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3b392c",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 8 column 1 (char 92)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e0fa9581006d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mjson_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mjson_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Source'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mjson_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 8 column 1 (char 92)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Iterate through the files in the directory and append each one into the dataframe.\n",
    "# This will only work correctly if the files have the exact same column names.\n",
    "df_list = []\n",
    "for f in files_csv:\n",
    "    data = pd.read_csv(str(file_path) + '/' + str(f), index_col=None, header=0)\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "for f in files_xlsx:\n",
    "    data = pd.read_excel(str(file_path) + '/' + str(f))\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "# Iterate through the json files and add data from each to a list.\n",
    "json_list = []\n",
    "for f in files_json:\n",
    "    with open(str(file_path) + '/' + str(f)) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        json_obj['Source'] = f\n",
    "        json_list.append(json_obj.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(json_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "    \n",
    "# Iterate through the xml files and add data from each to a list.\n",
    "xml_list = []\n",
    "for f in files_xml:\n",
    "    # create element tree object \n",
    "    tree = ET.parse(str(file_path) + '/' + str(f))\n",
    "    # get root element \n",
    "    root = tree.getroot()\n",
    "    # create dictionary from XML tags and values\n",
    "    itemdict = {}\n",
    "    for item in root:\n",
    "        itemdict[item.tag] = item.text\n",
    "    itemdict['Source'] = f\n",
    "    xml_list.append(itemdict.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(xml_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "\n",
    "# Combine all the data frames in the list into a single data frame.    \n",
    "df =  pd.concat(df_list, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# See how many rows the data frame has.\n",
    "print(len(df.index))\n",
    "\n",
    "# Show the data in the data frame.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the error above, I know my issue is with the format of the json files, but I'm lost on how to fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c74a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-19\n",
      "/Users/reinhardts/Documents/myProject/NURS6806/exerPythCombineFiles/FileTypes/NewCombinedFile_2021-10-19.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-229bb3bb364d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File saved.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Save the dataframe to a new combined csv file.\n",
    "\n",
    "# Add today's date to the name of the new file.\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(today)\n",
    "\n",
    "filename = str(file_path) + '/' + 'NewCombinedFile_' + str(today) + '.csv'\n",
    "print(filename)\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "print('File saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b17611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
